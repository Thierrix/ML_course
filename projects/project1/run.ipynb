{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from cleaning_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/dataset/dataset\"\n",
    "x_train, x_test, y_train, train_ids, test_ids, y_test, labels =  load_csv_data(DATA_PATH, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from utils import remove_features, find_key_by_value\n",
    "\n",
    "#Defining some constants\n",
    "ACCEPTABLE_NAN_PERCENTAGE = 0.3\n",
    "dictionary_features = {\n",
    "    **dict.fromkeys(['_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR',\n",
    "                     'DISPCODE', 'SEQNO', '_PSU', 'SEX', 'QSTVER', '_STSTR',\n",
    "                     '_STRWT', '_RAWRAKE', '_WT2RAKE', '_DUALUSE', '_LLCPWT',\n",
    "                     '_DRDXAR1', '_RACE_G1', '_AGE80', '_AGE_G', 'HTIN4', 'HTM4', '_BMI5', '_BMI5CAT',\n",
    "                     'FTJUDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_MISFRTN', '_MISVEGN',\n",
    "                     '_FRTRESP', '_VEGRESP', '_FRUTSUM', '_FRUTSUM', '_FRT16', '_VEG23', '_FRUITEX',\n",
    "                     '_VEGETEX', 'QSTLANG', 'FRUTDA1_', '_VEGESUM'\n",
    "                   \n",
    "                    ], {}),\n",
    "    \n",
    "    **dict.fromkeys(['ALCDAY5', 'STRENGTH'], {'dont_know_not_sure' : 777, 'none' : 888, 'refused' : 999}),\n",
    "    \n",
    "    **dict.fromkeys(['PHYSHLTH', 'MENTHLTH'], {'dont_know_not_sure' : 77, 'none' : 88, 'refused' : 99}),\n",
    "    \n",
    "    **dict.fromkeys(['CHILDREN'], {'none' : 88, 'refused' : 99}),\n",
    "    \n",
    "     **dict.fromkeys(['INCOME2', '_PRACE1', '_MRACE1'], {'dont_know_not_sure' : 77, 'refused' : 99}),\n",
    "\n",
    "    **dict.fromkeys(['FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVORANG', 'FVGREEN', 'VEGETAB1'], {'never' : 555, 'dont_know_not_sure' : 777, 'refused' : 999}),\n",
    "    \n",
    "     **dict.fromkeys(['GENHLTH', 'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'BPHIGH4',\n",
    "                      'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3', 'ASTHMA3',\n",
    "                      'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'ADDEPEV2',\n",
    "                      'CHCKIDNY', 'DIABETE3', 'RENTHOM1', 'VETERAN3', 'INTERNET',\n",
    "                     'QLACTLM2', 'USEEQUIP', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES',\n",
    "                      'DIFFALON', 'SMOKE100', 'USENOW3', 'EXERANY2', 'FLUSHOT6', 'PNEUVAC3',\n",
    "                      'HIVTST6', 'DRNKANY5'\n",
    "                     ], {'dont_know_not_sure' : 7, 'refused' : 9}),\n",
    "    \n",
    "    **dict.fromkeys(['CHECKUP1', 'SEATBELT'], {'dont_know_not_sure' : 7, 'never' : 8, 'refused' : 9}),\n",
    "    \n",
    "    **dict.fromkeys(['MARITAL', 'EDUCA', 'EMPLOY1', '_CHISPNC', '_RFHLTH',\n",
    "                      '_HCVU651', '_RFHYPE5', '_CHOLCHK', '_RFCHOL', '_LTASTH1',\n",
    "                      '_CASTHM1', '_ASTHMS1', '_HISPANC', '_RACE', '_RACEG21',\n",
    "                      '_RACEGR3', '_RFBMI5', '_CHLDCNT', '_EDUCAG', '_INCOMG',\n",
    "                      '_SMOKER3', '_RFSMOK3', '_RFBING5', '_RFDRHV5', '_FRTLT1',\n",
    "                     '_VEGLT1', '_TOTINDA', 'PAMISS1_', '_PACAT1', '_PAINDX1', '_PA150R2',\n",
    "                     '_PA300R2', '_PA30021', '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTACT1',\n",
    "                     '_LMTWRK1', '_LMTSCL1', '_RFSEAT2', '_RFSEAT3', '_AIDTST3'\n",
    "                     ], {'refused' : 9}),\n",
    "    \n",
    "    **dict.fromkeys(['HEIGHT3', 'WEIGHT2'], {'dont_know_not_sure' : 7777, 'refused' : 9999}),\n",
    "    \n",
    "    **dict.fromkeys(['_AGEG5YR'], {'refused' : 14}),\n",
    "\n",
    "    **dict.fromkeys(['_AGE65YR'], {'refused' : 3}),\n",
    "\n",
    "    **dict.fromkeys(['WTKG3'], {'refused' : 99999}),\n",
    "    **dict.fromkeys(['DROCDY3_'], {'refused' : 900}),\n",
    "    **dict.fromkeys(['_DRNKWEK'], {'refused' : 99900}),\n",
    "     **dict.fromkeys(['FC60_', 'MAXVO2_'], {'refused' : 999}),\n",
    "     **dict.fromkeys(['STRFREQ_'], {'refused' : 99}),\n",
    "   \n",
    "}\n",
    "\n",
    "category_features = {'categorical' : ['HLTHPLN1','_STATE','FMONTH','IDATE', 'IMONTH', 'DISPCODE', 'PERSDOC2',\n",
    "                             'MEDCOST', 'CHECKUP1', 'BPHIGH4', 'BLOODCHO', 'CHOLCHK', 'TOLDHI2', 'CVDSTRK3',\n",
    "                            'ASTHMA3', 'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1', 'HAVARTH3', 'ADDEPEV2', 'CHCKIDNY'\n",
    "                             'DIABETE3','SEX', 'MARITAL', 'EDUCA', 'RENTHOM1', 'VETERAN3', 'EMPLOY1', 'INCOME2', 'INTERNET', 'QLACTLM2',\n",
    "                             'USEEQUIP', 'BLIND', 'DECIDE', 'DIFFWALK', 'DIFFDRES', 'DIFFALON', 'SMOKE100', 'USENOW3', 'EXERANY2', 'SEATBELT',\n",
    "                             'FLUSHOT6', 'PNEUVAC3', 'HIVTST6', 'QSTVER', 'QSTLANG','_CHISPNC', '_DUALUSE', '_RFHLTH', '_HCVU651', '_RFHYPE5',\n",
    "                             '_CHOLCHK', '_RFCHOL', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_DRDXAR1', '_PRACE1', '_MRACE1', '_HISPANC', '_RACE',\n",
    "                             '_RACEG21', '_RACEGR3',  '_RACE_G1', '_AGEG5YR', '_AGE65YR', '_AGE_G', '_BMI5CAT', '_RFBMI5', '_CHLDCNT', '_EDUCAG',\n",
    "                             '_INCOMG', '_SMOKER3', '_RFSMOK3', 'DRNKANY5', '_RFBING5', '_RFDRHV5', '_MISFRTN', '_MISVEGN', '_FRTRESP', '_VEGRESP',\n",
    "                             '_FRTLT1', '_VEGLT1', '_FRT16', '_VEG23', '_FRUITEX', '_VEGETEX', '_TOTINDA', 'PAMISS1_', '_PACAT1', '_PAINDX1',\n",
    "                             '_PA150R2', '_PA300R2', '_PA30021', '_PASTRNG', '_PAREC1', '_PASTAE1', '_LMTACT1', '_LMTWRK1', '_LMTSCL1',\n",
    "                             '_RFSEAT2', '_RFSEAT3', '_AIDTST3', 'IYEAR', '_RFSMOK3'\n",
    "                             \n",
    "                             \n",
    "                            ],\n",
    "\n",
    "            \n",
    "            'continuous' : ['WEIGHT2', 'HEIGHT3', 'ALCDAY5', 'FRUITJU1', 'FRUIT1', 'FVBEANS', 'FVGREEN',\n",
    "                            'FVORANG', 'VEGETAB1', 'STRENGTH', '_AGE80', 'HTIN4', 'WTKG3', 'HTM4', '_BMI5', 'DROCDY3_',\n",
    "                           '_DRNKWEK', 'FTJUDA1_', 'BEANDAY_', 'GRENDAY_', 'ORNGDAY_', 'VEGEDA1_', '_FRUTSUM', '_FRUTSUM',\n",
    "                           'MAXVO2_', 'FC60_', 'STRFREQ_', 'PHYSHLTH', 'IDAY', 'CHILDREN'],\n",
    "            \n",
    "            'not_sure' : ['SEQNO', '_PSU' , '_STSTR', '_STRWT', '_RAWRAKE', ' _WT2RAKE', '_LLCPWT']\n",
    "           }\n",
    "\n",
    "def clean_data_x(x_train, labels):\n",
    "    \"\"\"\n",
    "    Cleaning data\n",
    "    :param x_train: training data\n",
    "    :return: cleaned data\n",
    "    \"\"\"\n",
    "    #Removing the first label which is the id\n",
    "    labels.pop(0) \n",
    "    features_number = x_train.shape[1]\n",
    "\n",
    "    #Removing columns with more than ACCEPTABLE_NAN_PERCENTAGE of NaN values\n",
    "    mask_nan_columns = [(np.count_nonzero(np.isnan(x_train[:, i]))/x_train.shape[0]) < ACCEPTABLE_NAN_PERCENTAGE for i in range (0, features_number)]\n",
    "    x_train = x_train[:, mask_nan_columns]\n",
    "\n",
    "    features_number = x_train.shape[1]\n",
    "    #Creating features list\n",
    "    features = list(dict.fromkeys(labels))\n",
    "    features = [features[i]  for i in range (0,features_number) if mask_nan_columns[i]]\n",
    "    features = {word: index for index, word in enumerate(features)}\n",
    "\n",
    "    #We handle the date and rescale some of the features\n",
    "    x_train = handling_data(x_train, features)\n",
    "\n",
    "    #We remove the features that are not useful\n",
    "    features, x_train = remove_features(x_train, ['WEIGHT2', 'HEIGHT3'], features)\n",
    "\n",
    "    x_train, features = handle_correlation(x_train, features)\n",
    "\n",
    "    x_train = apply_pca(x_train)\n",
    "\n",
    "    return x_train\n",
    "\n",
    "def handling_data(x_train, features):\n",
    "    \"\"\"\n",
    "    Handling and modifying data because of special values and scaling some values\n",
    "    :param x_train: training data\n",
    "    :return: modified data\n",
    "    \"\"\"\n",
    "    #Normalizing data\n",
    "    for feature in features.keys() :\n",
    "    \n",
    "        dict_special_value_handle = dictionary_features.get(feature)\n",
    "        if dict_special_value_handle is not None :\n",
    "            for special_value in dict_special_value_handle.keys() :\n",
    "                #For special values meaning not sure, we change by the median\n",
    "                if special_value == 'dont_know_not_sure' :\n",
    "                    x_train[x_train[:, features[feature]] == dict_special_value_handle[special_value], features[feature]] = np.nanmedian(x_train[:, features[feature]])\n",
    "                \n",
    "                #For special values meaning none, we change by 0\n",
    "                elif special_value == 'never' or special_value == 'none'  :\n",
    "                    x_train[x_train[:, features[feature]] == dict_special_value_handle[special_value], features[feature]] = 0\n",
    "                    \n",
    "                #For special values meaning refused, we change by NaN\n",
    "                elif special_value == 'refused' :\n",
    "                    x_train[x_train[:, features[feature]] == dict_special_value_handle[special_value], features[feature]] = np.nan\n",
    "    \n",
    "    x_train = day_week_month_rescale(x_train, 'STRENGTH', 1, features)\n",
    "    x_train = day_week_month_rescale(x_train, 'ALCDAY5', 1, features)\n",
    "    x_train = day_week_month_rescale(x_train, 'FRUIT1', 2, features)\n",
    "    x_train = day_week_month_rescale(x_train, 'FVBEANS', 2, features)\n",
    "    x_train = day_week_month_rescale(x_train, 'FVORANG', 2, features)\n",
    "    x_train = day_week_month_rescale(x_train, 'FVGREEN', 2, features)\n",
    "    x_train = day_week_month_rescale(x_train, 'VEGETAB1', 2, features)\n",
    "    x_train = day_week_month_rescale(x_train, 'FRUITJU1', 2, features)\n",
    "\n",
    "    return x_train\n",
    "\n",
    "def day_week_month_rescale(x, feature_name, scaling_mode, features):\n",
    "    \"\"\"\n",
    "    Rescale the values of the feature_name\n",
    "    :param x: training data\n",
    "    :param feature_name: feature name\n",
    "    :param scaling_mode: scaling mode\n",
    "    :param features: features list\n",
    "    :return: modified data\n",
    "    \"\"\"\n",
    "\n",
    "    mask_three_hundred = x[:, features[feature_name]] > 300\n",
    "    mask_two_hundred = (x[:, features[feature_name]] >= 200) & (x[:, features[feature_name]] < 300)\n",
    "    mask_one_hundred = (x[:, features[feature_name]] >= 100) &(x[:, features[feature_name]] < 200) \n",
    "        \n",
    "    if scaling_mode == 1 : \n",
    "        x[mask_one_hundred , features[feature_name]] = (x[mask_one_hundred, features[feature_name]] -100)*4.33\n",
    "        x[mask_two_hundred, features[feature_name]] = (x[mask_two_hundred, features[feature_name]] -200)\n",
    "        \n",
    "    elif scaling_mode == 2:\n",
    "        x[x[:, features[feature_name]] == 300, features[feature_name]] = 0\n",
    "        x[mask_one_hundred , features[feature_name]] = (x[mask_one_hundred, features[feature_name]] -100)*(4.33*7)\n",
    "        x[mask_two_hundred, features[feature_name]] = (x[mask_two_hundred, features[feature_name]] -200)*(4.33)\n",
    "        x[mask_three_hundred, features[feature_name]] = (x[mask_three_hundred, features[feature_name]] -300)\n",
    "\n",
    "    return x\n",
    "\n",
    "def handle_correlation(x_train, features):\n",
    "    \"\"\"\n",
    "    Handling correlation between features\n",
    "    :param x_train: training data\n",
    "    :param features: features list\n",
    "    :return: modified and correlation handled data\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace NaN in categorical features with the median value\n",
    "    for feature in category_features['continuous']:\n",
    "        if feature in features.keys() :\n",
    "            median_value = np.nanmedian(x_train[:, features[feature]])\n",
    "            x_train[: ,features[feature]] = np.nan_to_num(x_train[:,features[feature]], nan = median_value)\n",
    "\n",
    "    # Replace NaN in categorical features with the most frequent (mode) value\n",
    "    for feature in category_features['categorical']:\n",
    "    \n",
    "        if feature in features.keys() :\n",
    "            values, counts = np.unique(x_train[:, features[feature]], return_counts=True)\n",
    "            most_represented_class = np.argmax(counts)\n",
    "            x_train[:,features[feature]] = np.nan_to_num(x_train[:,features[feature]], nan = most_represented_class)\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    no_nan_in_row_mask = ~np.isnan(x_train).any(axis=1)\n",
    "    x_train_no_nan = x_train[no_nan_in_row_mask, :]\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    features_correlation = np.corrcoef(x_train_no_nan, rowvar=False)\n",
    "\n",
    "    # Find the features that are highly correlated\n",
    "    correlation_limit = 0.7\n",
    "    correlation_tuple_list = []\n",
    "    correlation_list = []\n",
    "    for i in range(x_train_no_nan.shape[1]) : \n",
    "        for j in range(i, x_train_no_nan.shape[1]) : \n",
    "            if i != j and features_correlation[i,j] >= correlation_limit : \n",
    "                \n",
    "                correlation_tuple_list.append((find_key_by_value(features, i) , find_key_by_value(features, j)))\n",
    "                correlation_list.append(find_key_by_value(features, i))\n",
    "                correlation_list.append(find_key_by_value(features, j))\n",
    "    \n",
    "    # Use np.unique to get counts of each element\n",
    "    correlation_list = np.array(correlation_list)\n",
    "    unique_elements, counts = np.unique(correlation_list, return_counts=True)\n",
    "    count_elements = dict(zip(unique_elements, counts))\n",
    "\n",
    "    features_to_remove = set()\n",
    "    # Iterate through the correlation tuples\n",
    "    for feature1, feature2 in correlation_tuple_list:\n",
    "        # Compare the counts of the two features\n",
    "        if count_elements[feature1] > count_elements[feature2]:\n",
    "            features_to_remove.add(feature2)\n",
    "        else:\n",
    "            features_to_remove.add(feature1)\n",
    "\n",
    "    # Remove the features from the features dictionary and x_train_modified\n",
    "    features, x_train = remove_features(x_train, list(features_to_remove), features)\n",
    "\n",
    "    # Update the features dictionary to reflect the new indices\n",
    "    features = {feature: i for i, feature in enumerate(features.keys())}\n",
    "\n",
    "    return x_train, features\n",
    "\n",
    "def apply_pca(x_train):\n",
    "    \"\"\"\n",
    "    Apply PCA to the data\n",
    "    :param x_train: training data\n",
    "    :return: pca applied data\n",
    "    \"\"\"\n",
    "    mean = np.nanmean(x_train, axis=0)\n",
    "    x_tilde = x_train - mean\n",
    "    cov_matrix = np.cov(x_tilde, rowvar=False)\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    eigvals = eigvals[::-1]\n",
    "    eigvecs = eigvecs[:, ::-1]\n",
    "\n",
    "    num_dimensions = 35\n",
    "    W = eigvecs[:, 0 : num_dimensions]\n",
    "    eg = eigvals[0 : num_dimensions]\n",
    "\n",
    "    x_pca = np.dot(x_tilde, W)\n",
    "    return x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'FRUIT1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_train_cleaned \u001b[38;5;241m=\u001b[39m clean_data_x(x_train, labels)\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_train_cleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_train_cleaned)\n",
      "Cell \u001b[1;32mIn[17], line 110\u001b[0m, in \u001b[0;36mclean_data_x\u001b[1;34m(x_train, labels)\u001b[0m\n\u001b[0;32m    107\u001b[0m features \u001b[38;5;241m=\u001b[39m {word: index \u001b[38;5;28;01mfor\u001b[39;00m index, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features)}\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m#We handle the date and rescale some of the features\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m x_train \u001b[38;5;241m=\u001b[39m handling_data(x_train, features)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m#We remove the features that are not useful\u001b[39;00m\n\u001b[0;32m    113\u001b[0m features, x_train \u001b[38;5;241m=\u001b[39m remove_features(x_train, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWEIGHT2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHEIGHT3\u001b[39m\u001b[38;5;124m'\u001b[39m], features)\n",
      "Cell \u001b[1;32mIn[17], line 147\u001b[0m, in \u001b[0;36mhandling_data\u001b[1;34m(x_train, features)\u001b[0m\n\u001b[0;32m    145\u001b[0m x_train \u001b[38;5;241m=\u001b[39m day_week_month_rescale(x_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTRENGTH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m, features)\n\u001b[0;32m    146\u001b[0m x_train \u001b[38;5;241m=\u001b[39m day_week_month_rescale(x_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALCDAY5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m, features)\n\u001b[1;32m--> 147\u001b[0m x_train \u001b[38;5;241m=\u001b[39m day_week_month_rescale(x_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFRUIT1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m, features)\n\u001b[0;32m    148\u001b[0m x_train \u001b[38;5;241m=\u001b[39m day_week_month_rescale(x_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFVBEANS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m, features)\n\u001b[0;32m    149\u001b[0m x_train \u001b[38;5;241m=\u001b[39m day_week_month_rescale(x_train, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFVORANG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m, features)\n",
      "Cell \u001b[1;32mIn[17], line 166\u001b[0m, in \u001b[0;36mday_week_month_rescale\u001b[1;34m(x, feature_name, scaling_mode, features)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mday_week_month_rescale\u001b[39m(x, feature_name, scaling_mode, features):\n\u001b[0;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    Rescale the values of the feature_name\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    :param x: training data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    :return: modified data\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     mask_three_hundred \u001b[38;5;241m=\u001b[39m x[:, features[feature_name]] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[0;32m    167\u001b[0m     mask_two_hundred \u001b[38;5;241m=\u001b[39m (x[:, features[feature_name]] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m) \u001b[38;5;241m&\u001b[39m (x[:, features[feature_name]] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m    168\u001b[0m     mask_one_hundred \u001b[38;5;241m=\u001b[39m (x[:, features[feature_name]] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m&\u001b[39m(x[:, features[feature_name]] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m200\u001b[39m) \n",
      "\u001b[1;31mKeyError\u001b[0m: 'FRUIT1'"
     ]
    }
   ],
   "source": [
    "x_train_cleaned = clean_data_x(x_train, labels)\n",
    "\n",
    "np.savetxt(\"x_train_cleaned.csv\", x_train_cleaned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
